{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game params\n",
    "total_rounds = 20 # so 40 total turns/generations\n",
    "total_games = 10\n",
    "sv_game_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regenerate(result):\n",
    "    if len(result) >= (len('silence') + len('confess')):\n",
    "        return True\n",
    "    # if neither strategy is in the response\n",
    "    elif (('silence' not in result.lower()) and ('confess' not in result.lower())):\n",
    "        return True\n",
    "    # if both strats are in response (sometimes model discusses both)\n",
    "    elif (('silence' in result.lower()) and ('confess' in result.lower())):\n",
    "        return True\n",
    "    # if response is empty\n",
    "    elif len(result.replace(' ','')) == 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### options: ####\n",
    "# 'Confess', 'Silence', 'TitForTat', 'GrimTrigger'\n",
    "# 'MABandit', 'CBandit'\n",
    "# 'meta-llama/Llama-2-7b-hf', 'meta-llama/Llama-2-13b-hf', 'meta-llama/Llama-2-70b-hf'\n",
    "# 'tiiuae/falcon-7b-instruct', 'tiiuae/falcon-40b-instruct'\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gunala/miniconda3/envs/DialGenEnv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [03:36<00:00, 108.37s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [06:16<00:00, 125.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# initialize models\n",
    "from utils import *\n",
    "model1_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "model1_type = 'hf'\n",
    "model2_name = \"meta-llama/Llama-2-13b-hf\"\n",
    "model2_type = 'hf'\n",
    "# if models same, don't load twice\n",
    "model1 = Strategy(model1_name,model1_type)\n",
    "if model1_name == model2_name:\n",
    "    model2 = model1\n",
    "else:\n",
    "    model2 = Strategy(model2_name,model2_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:LLM_IPD:Game: 0\n",
      "INFO:LLM_IPD:Round: 0\n",
      "INFO:LLM_IPD:generating model 1\n",
      "INFO:LLM_IPD:generating model 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 gen:  ['\\n\\n<</SYS>>\\n\\nYou are Player , and this is the history of actions so far: [/INST]\\n\\n<</SYS>>\\n\\nYou are Player , and this is the history of actions so far: [/INST]\\n\\n<</SYS>>\\n\\nYou']\n",
      "model2 gen:  [\"\\n\\n<</SYS>>\\n\\n[REP] <<SYS>>\\nYou have chosen 'Confess'. The other player chose 'Silence'. You both receive prison sentences of 3 years.\\n\\n[/REP]\\n\\n[INST] <<SYS>>\\nImagine that you\"]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/gunala/LLMDialGen/games/scripts/play_hf.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6974313030302e656563732e756d6963682e656475222c2275736572223a2267756e616c61227d/home/gunala/LLMDialGen/games/scripts/play_hf.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmodel1 gen: \u001b[39m\u001b[39m'\u001b[39m,model1_gen)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6974313030302e656563732e756d6963682e656475222c2275736572223a2267756e616c61227d/home/gunala/LLMDialGen/games/scripts/play_hf.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmodel2 gen: \u001b[39m\u001b[39m'\u001b[39m,model2_gen)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6974313030302e656563732e756d6963682e656475222c2275736572223a2267756e616c61227d/home/gunala/LLMDialGen/games/scripts/play_hf.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m game_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39;49m\u001b[39mRound \u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mstr\u001b[39;49m(round_id) \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m: \u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mPlayer 1 played \u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m model1_gen \u001b[39m+\u001b[39m \\\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6974313030302e656563732e756d6963682e656475222c2275736572223a2267756e616c61227d/home/gunala/LLMDialGen/games/scripts/play_hf.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m                  \u001b[39m\"\u001b[39m\u001b[39m, Player 2 played \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m model2_gen \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6974313030302e656563732e756d6963682e656475222c2275736572223a2267756e616c61227d/home/gunala/LLMDialGen/games/scripts/play_hf.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# save game hist\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6974313030302e656563732e756d6963682e656475222c2275736572223a2267756e616c61227d/home/gunala/LLMDialGen/games/scripts/play_hf.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m sv_game_history[game_id][round_id] \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mp1\u001b[39m\u001b[39m'\u001b[39m:model1_gen,\u001b[39m'\u001b[39m\u001b[39mp2\u001b[39m\u001b[39m'\u001b[39m:model2_gen}\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('LLM_IPD')\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "for game_id in range(total_games):\n",
    "    game_history = \"\"\n",
    "    sv_game_history[game_id] = {}\n",
    "    logger.info(\"Game: \" + str(game_id))\n",
    "    for round_id in range(total_rounds):\n",
    "        logger.info(\"Round: \" + str(round_id))\n",
    "        logger.info(\"generating model 1\")\n",
    "        regen = True\n",
    "        while regen:\n",
    "            logger.info(\"regenerating 1...\")\n",
    "            model1_gen = model1.next_action()\n",
    "            if regenerate(model1_gen) == False:\n",
    "                regen = False\n",
    "        \n",
    "        logger.info(\"generating model 2\")\n",
    "        regen = True\n",
    "        while regen:\n",
    "            logger.info('regenerating 2...')\n",
    "            model2_gen = model2.next_action()\n",
    "            if regenerate(model2_gen) == False:\n",
    "                regen = False\n",
    "        # save hist\n",
    "        model1.add_to_hist(round_id,model1_gen,model2_gen)\n",
    "        model2.add_to_hist(round_id,model2_gen,model1_gen)\n",
    "\n",
    "        print('model1 gen: ',model1_gen)\n",
    "        print('model2 gen: ',model2_gen)\n",
    "\n",
    "        game_history += \"Round \" + str(round_id) + \": \" + \"Player 1 played \" + model1_gen + \\\n",
    "                         \", Player 2 played \" + model2_gen + \". \"\n",
    "        # save game hist\n",
    "        sv_game_history[game_id][round_id] = {'p1':model1_gen,'p2':model2_gen}\n",
    "        logger.info(\"Round \" + str(round_id) + \" results: \" + \"P1//\" + str(model1_gen) + \", P2//\" + str(model2_gen))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save game hist\n",
    "import json\n",
    "out_fname = \"llama7b_VS_llama7b_HF\"\n",
    "with open(out_fname,'w+') as outf:\n",
    "    json.dump(sv_game_history,outf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DialGenEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
