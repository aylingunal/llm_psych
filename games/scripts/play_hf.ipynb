{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game params\n",
    "total_rounds = 20 # so 40 total turns/generations\n",
    "total_games = 10\n",
    "sv_game_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(player_id,game_history):\n",
    "    system_prompt = \"Imagine that you and your criminal partner have been placed under arrest and are being interrogated in separate rooms. Both you and your partner have the option to either 'Silence' or 'Confess'. If both of you are silent, you both receive a prison sentence of 1 year. If one of you confesses and the other stays silent, the partner that confesses will receive a prison sentence of 0 years while the one of the stayed silent will receive a sentence of 5 years. If both of you confess, you will both receive sentences of 3 years. Your goal is to minimize your prison sentence. Respond in one word, either 'Silence' or 'Confess'.\"\n",
    "    user_prompt = \"You are Player \" + player_id + \", and this is the history of actions so far: \" + game_history + \". Will you choose 'Silence' or 'Confess' in the next round? Please answer in 1 word.\"\n",
    "\n",
    "    return system_prompt,user_prompt\n",
    "\n",
    "def regenerate(result):\n",
    "    if len(result) >= (len('silence') + len('confess')):\n",
    "        return True\n",
    "    # if neither strategy is in the response\n",
    "    elif (('silence' not in result.lower()) and ('confess' not in result.lower())):\n",
    "        return True\n",
    "    # if both strats are in response (sometimes model discusses both)\n",
    "    elif (('silence' in result.lower()) and ('confess' in result.lower())):\n",
    "        return True\n",
    "    # if response is empty\n",
    "    elif len(result.replace(' ','')) == 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### options: ####\n",
    "# 'Confess', 'Silence', 'TitForTat', 'GrimTrigger'\n",
    "# 'MABandit', 'CBandit'\n",
    "# 'meta-llama/Llama-2-7b-hf', 'meta-llama/Llama-2-13b-hf', 'meta-llama/Llama-2-70b-hf'\n",
    "# 'tiiuae/falcon-7b-instruct', 'tiiuae/falcon-40b-instruct'\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gunala/miniconda3/envs/DialGenEnv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# initialize models\n",
    "from utils import *\n",
    "model1_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "model1_type = 'hf'\n",
    "model2_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "model2_type = 'hf'\n",
    "# if models same, don't load twice\n",
    "model1 = Strategy(model1_name,model1_type)\n",
    "if model1_name == model2_name:\n",
    "    model2 = model1\n",
    "else:\n",
    "    model2 = Strategy(model2_name,model2_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('LLM_IPD')\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "# for testing\n",
    "total_games = 1\n",
    "total_rounds = 2\n",
    "\n",
    "for game_id in range(total_games):\n",
    "    game_history = \"\"\n",
    "    sv_game_history[game_id] = {}\n",
    "    logger.info(\"Game: \" + str(game_id))\n",
    "    for round_id in range(total_rounds):\n",
    "        logger.info(\"Round: \" + str(round_id))\n",
    "        logger.info(\"generating model 1\")\n",
    "        model1_gen = model1.next_action()\n",
    "        logger.info(\"generating model 2\")\n",
    "        model2_gen = model2.next_action()\n",
    "        # save hist\n",
    "        model1.add_to_hist(round_id,model1_gen,model2_gen)\n",
    "        model2.add_to_hist(round_id,model2_gen,model1_gen)\n",
    "\n",
    "        print('model1 gen: ',model1_gen)\n",
    "        print('model2 gen: ',model2_gen)\n",
    "\n",
    "        \n",
    "        # game_history += \"Round \" + str(round_id) + \": \" + \"Player 1 played \" + model1_gen + \\\n",
    "        #                  \", Player 2 played \" + model2_gen + \". \"\n",
    "        # # save game hist\n",
    "        # sv_game_history[game_id][round_id] = {'p1':model1_gen,'p2':model2_gen}\n",
    "        logger.info(\"Round \" + str(round_id) + \" results: \" + \"P1//\" + str(model1_gen) + \", P2//\" + str(model2_gen))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save game hist\n",
    "import json\n",
    "out_fname = \"llama7b_VS_llama70b\"\n",
    "with open(out_fname,'w+') as outf:\n",
    "    json.dump(sv_game_history,outf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DialGenEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
