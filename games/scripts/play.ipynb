{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing out the logits thing here\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import torch\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1,2,3\"\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('LLM_IPD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google/gemma-7b\n",
      "aegunal/FT_IPD_gemma7b\n",
      "mistralai/Mistral-7B-v0.1\n",
      "aegunal/FT_IPD_mistral7b\n",
      "meta-llama/Llama-2-7b-hf\n",
      "aegunal/FT_IPD_llama7b\n",
      "tiiuae/falcon-7b\n"
     ]
    }
   ],
   "source": [
    "print_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a78f59884f34200aba4e4fa92cd0ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed5d48164824f0baa9f6b681f55935e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize models\n",
    "model2 = PDModel(model_name_in=\"mistralai/Mistral-7B-v0.1\",\n",
    "                 player_id_in=\"2\")\n",
    "model1 = PDModel(model_name_in=\"mistralai/Mistral-7B-v0.1\",\n",
    "                 player_id_in=\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:LLM_IPD:Game: 0\n",
      "INFO:LLM_IPD:Round: 0\n",
      "INFO:LLM_IPD:generating model 1\n",
      "/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.75` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/transformers/generation/utils.py:1477: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 0 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 1\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 1 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 2\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 2 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 3\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 3 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 4\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 4 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 5\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 5 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 6\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 6 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 7\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 7 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 8\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 8 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 9\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 9 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Game: 1\n",
      "INFO:LLM_IPD:Round: 0\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 0 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 1\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 1 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 2\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 2 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 3\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 3 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 4\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 4 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 5\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 5 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 6\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 6 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 7\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 7 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 8\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 8 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 9\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 9 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Game: 2\n",
      "INFO:LLM_IPD:Round: 0\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 0 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 1\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 1 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 2\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 2 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 3\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 3 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 4\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 4 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 5\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 5 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 6\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 6 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 7\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 7 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 8\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 8 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 9\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 9 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Game: 3\n",
      "INFO:LLM_IPD:Round: 0\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 0 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 1\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 1 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 2\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 2 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 3\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 3 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 4\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 4 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 5\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 5 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 6\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 6 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 7\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 7 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 8\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 8 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 9\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 9 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Game: 4\n",
      "INFO:LLM_IPD:Round: 0\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 0 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 1\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 1 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 2\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 2 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 3\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 3 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 4\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 4 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 5\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 5 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 6\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 6 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 7\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 7 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 8\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 8 results: P1//Silence, P2//Silence\n",
      "INFO:LLM_IPD:Round: 9\n",
      "INFO:LLM_IPD:generating model 1\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:generating model 2\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "INFO:LLM_IPD:model 1, model 2 actions: Silence,Silence\n",
      "INFO:LLM_IPD:Round 9 results: P1//Silence, P2//Silence\n"
     ]
    }
   ],
   "source": [
    "num_rounds = 20\n",
    "num_games = 10\n",
    "sv_game_history = {}\n",
    "\n",
    "for game_id in range(num_games):\n",
    "    # game_history = \"\"\n",
    "    sv_game_history[game_id] = {}\n",
    "    logger.info(\"Game: \" + str(game_id))\n",
    "    for round_id in range(num_rounds):\n",
    "        logger.info(\"Round: \" + str(round_id))\n",
    "\n",
    "        logger.info(\"generating model 1\")\n",
    "        model1_gen = model1.next_action_hf()['action']\n",
    "        logger.info(\"generating model 2\")\n",
    "        model2_gen = model2.next_action_hf()['action']\n",
    "\n",
    "        logger.info(\"model 1, model 2 actions: \" + model1_gen + ',' + model2_gen)\n",
    "        # game_history += \"Round \" + str(round_id) + \": \" + \"Player 1 played \" + model1_gen + \\\n",
    "        #                  \", Player 2 played \" + model2_gen + \". \"\n",
    "        # save game hist\n",
    "        sv_game_history[game_id][round_id] = {'p1':model1_gen,'p2':model2_gen}\n",
    "        logger.info(\"Round \" + str(round_id) + \" results: \" + \"P1//\" + str(model1_gen) + \", P2//\" + str(model2_gen))\n",
    "        # update game histories for individual models\n",
    "        model1.add_to_hist(round_id, model1_gen, model2_gen)\n",
    "        model2.add_to_hist(round_id, model2_gen, model1_gen)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "output_dirname = \"/home/gunala/LLMDialGen/games/scripts/prompt3_scoresmethod/\"\n",
    "output_fname = \"mistral7b_VS_falcon7B\"\n",
    "with open(output_dirname + output_fname,'w+') as outf:\n",
    "    json.dump(sv_game_history,outf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DialGenEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
