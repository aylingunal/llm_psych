{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_TOKEN'] = \"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\" # read token\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1,2,3\"\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which model to ft\n",
    "model_id = \"tiiuae/falcon-7b\" # \"meta-llama/Llama-2-7b-hf\"\n",
    "                                      # \"meta-llama/Llama-2-13b-hf\"\n",
    "                                      # \"openai-community/gpt2\"\n",
    "                                      # \"mistralai/Mistral-7B-v0.1\"\n",
    "                                      # \"google/gemma-7b\"\n",
    "                                      # \"tiiuae/falcon-7b\"\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bc71b739c74e0d8d429654dc5ca95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, \\\n",
    "                         AutoModelForCausalLM\n",
    "\n",
    "if model_id == \"meta-llama/Llama-2-7b-hf\" or model_id == \"meta-llama/Llama-2-13b-hf\" :\n",
    "    from transformers import LlamaTokenizer, LlamaForCausalLM, LlamaForSequenceClassification\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "    model = LlamaForCausalLM.from_pretrained(model_id,\n",
    "                                                quantization_config=bnb_config,)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "elif model_id == \"google/gemma-7b\":\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                                    quantization_config=bnb_config)\n",
    "elif model_id == \"mistralai/Mistral-7B-v0.1\":\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                                    quantization_config=bnb_config)\n",
    "elif model_id == \"tiiuae/falcon-7b\":\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                                 quantization_config=bnb_config)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "elif model_id == \"openai-community/gpt2\":\n",
    "    from transformers import GPT2Tokenizer, GPT2Model\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = GPT2Model.from_pretrained('gpt2')\n",
    "else:\n",
    "    model = None\n",
    "    tokenizer = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', FalconForCausalLM(\n",
      "  (transformer): FalconModel(\n",
      "    (word_embeddings): Embedding(65024, 4544)\n",
      "    (h): ModuleList(\n",
      "      (0-31): 32 x FalconDecoderLayer(\n",
      "        (self_attention): FalconAttention(\n",
      "          (rotary_emb): FalconRotaryEmbedding()\n",
      "          (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "          (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): FalconMLP(\n",
      "          (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "          (act): GELU(approximate='none')\n",
      "          (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "        )\n",
      "        (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4544, out_features=65024, bias=False)\n",
      "))\n",
      "('transformer', FalconModel(\n",
      "  (word_embeddings): Embedding(65024, 4544)\n",
      "  (h): ModuleList(\n",
      "    (0-31): 32 x FalconDecoderLayer(\n",
      "      (self_attention): FalconAttention(\n",
      "        (rotary_emb): FalconRotaryEmbedding()\n",
      "        (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "        (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "        (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (mlp): FalconMLP(\n",
      "        (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "        (act): GELU(approximate='none')\n",
      "        (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "      )\n",
      "      (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.word_embeddings', Embedding(65024, 4544))\n",
      "('transformer.h', ModuleList(\n",
      "  (0-31): 32 x FalconDecoderLayer(\n",
      "    (self_attention): FalconAttention(\n",
      "      (rotary_emb): FalconRotaryEmbedding()\n",
      "      (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "      (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "      (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (mlp): FalconMLP(\n",
      "      (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "      (act): GELU(approximate='none')\n",
      "      (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "    )\n",
      "    (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "))\n",
      "('transformer.h.0', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.0.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.0.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.0.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.0.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.0.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.0.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.0.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.0.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.0.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.0.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.1', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.1.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.1.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.1.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.1.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.1.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.1.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.1.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.1.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.1.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.1.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.2', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.2.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.2.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.2.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.2.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.2.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.2.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.2.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.2.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.2.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.2.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.3', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.3.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.3.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.3.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.3.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.3.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.3.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.3.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.3.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.3.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.3.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.4', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.4.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.4.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.4.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.4.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.4.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.4.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.4.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.4.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.4.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.4.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.5', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.5.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.5.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.5.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.5.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.5.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.5.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.5.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.5.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.5.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.5.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.6', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.6.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.6.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.6.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.6.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.6.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.6.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.6.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.6.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.6.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.6.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.7', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.7.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.7.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.7.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.7.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.7.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.7.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.7.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.7.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.7.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.7.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.8', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.8.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.8.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.8.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.8.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.8.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.8.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.8.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.8.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.8.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.8.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.9', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.9.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.9.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.9.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.9.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.9.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.9.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.9.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.9.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.9.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.9.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.10', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.10.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.10.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.10.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.10.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.10.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.10.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.10.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.10.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.10.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.10.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.11', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.11.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.11.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.11.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.11.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.11.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.11.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.11.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.11.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.11.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.11.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.12', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.12.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.12.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.12.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.12.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.12.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.12.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.12.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.12.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.12.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.12.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.13', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.13.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.13.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.13.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.13.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.13.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.13.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.13.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.13.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.13.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.13.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.14', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.14.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.14.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.14.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.14.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.14.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.14.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.14.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.14.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.14.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.14.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.15', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.15.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.15.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.15.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.15.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.15.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.15.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.15.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.15.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.15.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.15.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.16', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.16.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.16.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.16.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.16.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.16.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.16.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.16.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.16.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.16.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.16.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.17', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.17.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.17.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.17.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.17.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.17.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.17.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.17.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.17.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.17.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.17.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.18', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.18.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.18.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.18.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.18.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.18.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.18.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.18.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.18.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.18.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.18.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.19', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.19.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.19.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.19.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.19.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.19.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.19.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.19.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.19.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.19.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.19.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.20', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.20.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.20.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.20.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.20.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.20.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.20.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.20.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.20.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.20.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.20.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.21', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.21.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.21.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.21.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.21.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.21.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.21.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.21.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.21.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.21.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.21.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.22', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.22.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.22.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.22.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.22.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.22.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.22.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.22.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.22.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.22.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.22.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.23', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.23.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.23.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.23.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.23.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.23.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.23.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.23.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.23.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.23.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.23.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.24', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.24.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.24.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.24.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.24.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.24.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.24.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.24.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.24.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.24.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.24.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.25', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.25.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.25.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.25.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.25.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.25.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.25.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.25.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.25.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.25.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.25.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.26', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.26.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.26.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.26.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.26.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.26.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.26.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.26.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.26.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.26.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.26.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.27', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.27.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.27.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.27.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.27.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.27.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.27.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.27.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.27.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.27.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.27.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.28', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.28.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.28.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.28.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.28.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.28.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.28.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.28.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.28.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.28.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.28.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.29', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.29.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.29.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.29.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.29.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.29.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.29.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.29.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.29.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.29.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.29.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.30', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.30.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.30.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.30.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.30.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.30.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.30.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.30.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.30.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.30.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.30.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.h.31', FalconDecoderLayer(\n",
      "  (self_attention): FalconAttention(\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "    (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "    (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (mlp): FalconMLP(\n",
      "    (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "    (act): GELU(approximate='none')\n",
      "    (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "  )\n",
      "  (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('transformer.h.31.self_attention', FalconAttention(\n",
      "  (rotary_emb): FalconRotaryEmbedding()\n",
      "  (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "  (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "))\n",
      "('transformer.h.31.self_attention.rotary_emb', FalconRotaryEmbedding())\n",
      "('transformer.h.31.self_attention.query_key_value', Linear4bit(in_features=4544, out_features=4672, bias=False))\n",
      "('transformer.h.31.self_attention.dense', Linear4bit(in_features=4544, out_features=4544, bias=False))\n",
      "('transformer.h.31.self_attention.attention_dropout', Dropout(p=0.0, inplace=False))\n",
      "('transformer.h.31.mlp', FalconMLP(\n",
      "  (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "  (act): GELU(approximate='none')\n",
      "  (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "))\n",
      "('transformer.h.31.mlp.dense_h_to_4h', Linear4bit(in_features=4544, out_features=18176, bias=False))\n",
      "('transformer.h.31.mlp.act', GELU(approximate='none'))\n",
      "('transformer.h.31.mlp.dense_4h_to_h', Linear4bit(in_features=18176, out_features=4544, bias=False))\n",
      "('transformer.h.31.input_layernorm', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('transformer.ln_f', LayerNorm((4544,), eps=1e-05, elementwise_affine=True))\n",
      "('lm_head', Linear(in_features=4544, out_features=65024, bias=False))\n"
     ]
    }
   ],
   "source": [
    "# check lora trainable layers\n",
    "def check_lora_trainable_layers():\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name, param.shape)\n",
    "\n",
    "def check_lora_target_mods():\n",
    "    for name in model.named_modules():\n",
    "        print(name)\n",
    "\n",
    "check_lora_target_mods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, TaskType\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "target_modules = []\n",
    "if (model_id == \"meta-llama/Llama-2-7b-hf\") or \\\n",
    "   (model_id == \"google/gemma-7b\"):\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    "elif model_id == \"mistralai/Mistral-7B-v0.1\":\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"down_proj\", \"up_proj\", \"gate_proj\"]\n",
    "elif model_id == \"tiiuae/falcon-7b\":\n",
    "    target_modules = [\"query_key_value\", \"dense\", \"dense_h_to_4h\", \"dense_4h_to_h\"]\n",
    "elif model_id == \"openai-community/gpt2\":\n",
    "    target_modules = [\"c_proj\"]\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=target_modules,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=['weight']\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ea3e02b28e45fa9a44d47a8c86cea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/12358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the data ready\n",
    "from utils import *\n",
    "data_ds = format_dat(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# fine-tuning!\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "output_dirname = \"saved_models/FT_\" + model_id\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "      per_device_train_batch_size=1,\n",
    "      per_device_eval_batch_size=1,\n",
    "      gradient_accumulation_steps=4, # this is for optimization\n",
    "      evaluation_strategy='epoch',\n",
    "      num_train_epochs=1,\n",
    "      warmup_steps=2,\n",
    "     # max_steps=1, # overrides num_train_epochs\n",
    "      learning_rate=2e-4,\n",
    "      fp16=True, # this is for optimization\n",
    "      logging_steps=1,\n",
    "      output_dir=output_dirname,\n",
    "      optim=\"paged_adamw_8bit\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=data_ds['train'],\n",
    "    eval_dataset=data_ds['test'],\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "Caught OutOfMemoryError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/peft/peft_model.py\", line 1083, in forward\n    return self.base_model(\n           ^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/peft/tuners/tuners_utils.py\", line 161, in forward\n    return self.model.forward(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/transformers/models/falcon/modeling_falcon.py\", line 1282, in forward\n    transformer_outputs = self.transformer(\n                          ^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/transformers/models/falcon/modeling_falcon.py\", line 1149, in forward\n    outputs = self._gradient_checkpointing_func(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/_compile.py\", line 24, in inner\n    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 489, in _fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/_dynamo/external_utils.py\", line 17, in inner\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/utils/checkpoint.py\", line 482, in checkpoint\n    return CheckpointFunction.apply(function, preserve, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/autograd/function.py\", line 553, in apply\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/utils/checkpoint.py\", line 261, in forward\n    outputs = run_function(*args)\n              ^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/transformers/models/falcon/modeling_falcon.py\", line 811, in forward\n    attn_outputs = self.self_attention(\n                   ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/transformers/models/falcon/modeling_falcon.py\", line 450, in forward\n    attn_output = F.scaled_dot_product_attention(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.11 GiB. GPU 0 has a total capacity of 10.75 GiB of which 340.50 MiB is free. Including non-PyTorch memory, this process has 10.42 GiB memory in use. Of the allocated memory 9.49 GiB is allocated by PyTorch, and 100.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/transformers/trainer.py:1961\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1961\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1964\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1967\u001b[0m ):\n\u001b[1;32m   1968\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/transformers/trainer.py:2902\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2901\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2902\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2905\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/transformers/trainer.py:2925\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2924\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2925\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2926\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2927\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:108\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    106\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 108\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: Caught OutOfMemoryError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/peft/peft_model.py\", line 1083, in forward\n    return self.base_model(\n           ^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/peft/tuners/tuners_utils.py\", line 161, in forward\n    return self.model.forward(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/transformers/models/falcon/modeling_falcon.py\", line 1282, in forward\n    transformer_outputs = self.transformer(\n                          ^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/transformers/models/falcon/modeling_falcon.py\", line 1149, in forward\n    outputs = self._gradient_checkpointing_func(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/_compile.py\", line 24, in inner\n    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 489, in _fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/_dynamo/external_utils.py\", line 17, in inner\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/utils/checkpoint.py\", line 482, in checkpoint\n    return CheckpointFunction.apply(function, preserve, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/autograd/function.py\", line 553, in apply\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/utils/checkpoint.py\", line 261, in forward\n    outputs = run_function(*args)\n              ^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/transformers/models/falcon/modeling_falcon.py\", line 811, in forward\n    attn_outputs = self.self_attention(\n                   ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gunala/miniconda3/envs/QLORAFTEnv/lib/python3.11/site-packages/transformers/models/falcon/modeling_falcon.py\", line 450, in forward\n    attn_output = F.scaled_dot_product_attention(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.11 GiB. GPU 0 has a total capacity of 10.75 GiB of which 340.50 MiB is free. Including non-PyTorch memory, this process has 10.42 GiB memory in use. Of the allocated memory 9.49 GiB is allocated by PyTorch, and 100.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574593dea68e4c409d15dcc2781fa707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/51.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/aegunal/FT_IPD_gemma7b/commit/1c8fb17c7003218ae7498a1f6a9c879e0f60bded', commit_message='Upload model', commit_description='', oid='1c8fb17c7003218ae7498a1f6a9c879e0f60bded', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['HF_TOKEN'] = \"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\" # write token\n",
    "hub_path = \"aegunal/FT_IPD_gemma7b\" #+ #model_id\n",
    "lora_model.push_to_hub(hub_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"saved_models/FT_IPD_gemma\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QLORAFTEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
